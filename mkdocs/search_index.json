{
    "docs": [
        {
            "location": "/", 
            "text": "CommunityHoneyNetwork\n\n\nHoneypot deployment and management automation\n\n\nSimple deployments for your platform\n\n\nCHN aims to make deployments honeypots and honeypot management tools easy and flexible. The default deployment method uses Docker Compose and Docker to deploy with a few simple commands.  Want to jump right in an get started?  Deploy a honeypot management server and sample honeypot in minutes with the \nQuickstart Guide\n.\n\n\nWith flexibility in mind, though, all parts of the project can be deployed separately, with or without containers, on CentOS or Ubuntu hosts.  Check the \nadvanced configuration documentation\n, \ninstalling and running without Docker\n, or \ndeploying to cloud providers\n.\n\n\nContributing\n\n\nContributions to the CommunityHoneyNetwork project are welcome!  Afterall, it's not much of a community without your help.  Documentation always needs help, individual projects each have their own issues or bugs that need to be addressed, and test coverage can always be improved.\n\n\nTo contribute, submit a pull request to one of the \nCommunityhoneyNetwork projects\n you'd like to work with. \n\n\nIn order to merge the pull request, it'll have to take the following steps:\n\n\n\n\nCreate the PR\n\n\nPass the automated Travis CI builds\n\n\nGet an \nLGTM\n (looks good to me) from a reviewer\n\n\nGet approval from an owner\n\n\n\n\nAcknowledgements\n\n\nCommunityHoneyNetwork is an adaptation of \nThreatstream's Modern Honey Network\n project, and several other excellent projects by the \nHoneynet Project\n and others.", 
            "title": "CommunityHoneyNetwork"
        }, 
        {
            "location": "/#communityhoneynetwork", 
            "text": "Honeypot deployment and management automation", 
            "title": "CommunityHoneyNetwork"
        }, 
        {
            "location": "/#simple-deployments-for-your-platform", 
            "text": "CHN aims to make deployments honeypots and honeypot management tools easy and flexible. The default deployment method uses Docker Compose and Docker to deploy with a few simple commands.  Want to jump right in an get started?  Deploy a honeypot management server and sample honeypot in minutes with the  Quickstart Guide .  With flexibility in mind, though, all parts of the project can be deployed separately, with or without containers, on CentOS or Ubuntu hosts.  Check the  advanced configuration documentation ,  installing and running without Docker , or  deploying to cloud providers .", 
            "title": "Simple deployments for your platform"
        }, 
        {
            "location": "/#contributing", 
            "text": "Contributions to the CommunityHoneyNetwork project are welcome!  Afterall, it's not much of a community without your help.  Documentation always needs help, individual projects each have their own issues or bugs that need to be addressed, and test coverage can always be improved.  To contribute, submit a pull request to one of the  CommunityhoneyNetwork projects  you'd like to work with.   In order to merge the pull request, it'll have to take the following steps:   Create the PR  Pass the automated Travis CI builds  Get an  LGTM  (looks good to me) from a reviewer  Get approval from an owner", 
            "title": "Contributing"
        }, 
        {
            "location": "/#acknowledgements", 
            "text": "CommunityHoneyNetwork is an adaptation of  Threatstream's Modern Honey Network  project, and several other excellent projects by the  Honeynet Project  and others.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/quickstart/", 
            "text": "QuickStart Guide\n\n\nDeploy a honeypot management server and sample honeypot in seconds.  This guide will deploy all the containers for the server on a single host using a default configuration.  The honeypot can be deployed on the same host or a separate host as desired.\n\n\nIf you'd like to deploy the server across multiple servers or modify the default configuration, or do other fun things, check out the \nAdvanced Configuration Guide\n.\n\n\nPrerequisites\n\n\nThe default deployment model uses Docker and Docker Compose to deploy containers for the project's tools, and so, require the following:\n\n\n\n\nDocker \n= 1.13.1\n\n\nDocker Compose \n= 1.15.0\n\n\n\n\nDeploying the Server\n\n\nCreate a new directory to hold your server deployment:\n\n\n$ mkdir chnserver\n$ cd chnserver\n\n\n\nCopy the following Docker Compose yaml, and save it as \ndocker-compose.yml\n:\n\n\nversion: '2'\nservices:\n  mongodb:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/mongodb.git\n    image: mongodb:centos\n    volumes:\n      - ./storage/mongodb:/var/lib/mongo:z\n  redis:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/redis.git\n    image: redis:centos\n    volumes:\n      - ./storage/redis:/var/lib/redis:z\n  hpfeeds:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/hpfeeds.git\n    image: hpfeeds:centos\n    links:\n      - mongodb:mongodb\n  mnemosyne:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/mnemosyne.git\n    image: mnemosyne:centos\n    links:\n      - mongodb:mongodb\n      - hpfeeds:hpfeeds\n  chnserver:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/CHN-Server.git\n    image: chnserver:centos\n    volumes:\n      - ./config/collector:/etc/collector:z\n    links:\n      - mongodb:mongodb\n      - redis:redis\n      - hpfeeds:hpfeeds\n    ports:\n      - \n80:80\n\n\n\n\n\nBuild the Docker images for the containers that make up the server:\n\n\n$ docker-compose build\n\n\n\nOnce the images are built, you start up your new server with:\n\n\n$ docker-compose up -d\n\n\n\nVerify your server is running with \ndocker-compose ps\n:\n\n\n$ docker-compose ps\n        Name                    Command           State           Ports         \n--------------------------------------------------------------------------------\nchnserver_chnserver_1   /sbin/runsvdir -P         Up      127.0.0.1:443-\n443/tcp\n                        /etc/service                      , 0.0.0.0:80-\n80/tcp  \nchnserver_hpfeeds_1     /sbin/runsvdir -P         Up      10000/tcp             \n                        /etc/service                                            \nchnserver_mnemosyne_1   /sbin/runsvdir -P         Up      8181/tcp              \n                        /etc/service                                            \nchnserver_mongodb_1     /sbin/runsvdir -P         Up      27017/tcp             \n                        /etc/service                                            \nchnserver_redis_1       /sbin/runsvdir -P         Up      6379/tcp              \n                        /etc/service \n\n\n\n\nWhen you're ready, the server can be stopped by running \ndocker-compose down\n.  For now, to continue with the setup, reset the default admin account (admin@localhost) password from the auto-generated one-time password:\n\n\n$ docker-compose exec chnserver python /opt/manual_password_reset.py\nEnter email address: admin@localhost\nEnter new password:\nEnter new password (again):\nuser found, updating password\n\n\n\n\nYou can now log into the web interface for your new honeypot management server.  In a browser, navigate to \nhttp://\nyour.host.name\n, using the hostname or IP of the host where the Docker containers are running.  You should be able to login using the \nadmin@localhost\n account and the password you just set.\n\n\nFinally, retrieve your DEPLOY_KEY.  This key is needed to deploy honeypots that talk with the server deployment.  Retrieve it with:\n\n\ndocker-compose exec chnserver awk '/DEPLOY_KEY/' /opt/config.py\n\n\nMake note of this key to use later (or alternatively, just run the above command again when you need it).\n\n\nNext Steps\n\n\nAt this point you have a functioning CommunityHoneyNetwork server, ready to register honeypots and start collecting data.  Next, try \ndeploying your first honeypot\n...", 
            "title": "QuickStart Guide"
        }, 
        {
            "location": "/quickstart/#quickstart-guide", 
            "text": "Deploy a honeypot management server and sample honeypot in seconds.  This guide will deploy all the containers for the server on a single host using a default configuration.  The honeypot can be deployed on the same host or a separate host as desired.  If you'd like to deploy the server across multiple servers or modify the default configuration, or do other fun things, check out the  Advanced Configuration Guide .", 
            "title": "QuickStart Guide"
        }, 
        {
            "location": "/quickstart/#prerequisites", 
            "text": "The default deployment model uses Docker and Docker Compose to deploy containers for the project's tools, and so, require the following:   Docker  = 1.13.1  Docker Compose  = 1.15.0", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/quickstart/#deploying-the-server", 
            "text": "Create a new directory to hold your server deployment:  $ mkdir chnserver\n$ cd chnserver  Copy the following Docker Compose yaml, and save it as  docker-compose.yml :  version: '2'\nservices:\n  mongodb:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/mongodb.git\n    image: mongodb:centos\n    volumes:\n      - ./storage/mongodb:/var/lib/mongo:z\n  redis:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/redis.git\n    image: redis:centos\n    volumes:\n      - ./storage/redis:/var/lib/redis:z\n  hpfeeds:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/hpfeeds.git\n    image: hpfeeds:centos\n    links:\n      - mongodb:mongodb\n  mnemosyne:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/mnemosyne.git\n    image: mnemosyne:centos\n    links:\n      - mongodb:mongodb\n      - hpfeeds:hpfeeds\n  chnserver:\n    build:\n      dockerfile: ./Dockerfile-centos\n      context: https://github.com/CommunityHoneyNetwork/CHN-Server.git\n    image: chnserver:centos\n    volumes:\n      - ./config/collector:/etc/collector:z\n    links:\n      - mongodb:mongodb\n      - redis:redis\n      - hpfeeds:hpfeeds\n    ports:\n      -  80:80   Build the Docker images for the containers that make up the server:  $ docker-compose build  Once the images are built, you start up your new server with:  $ docker-compose up -d  Verify your server is running with  docker-compose ps :  $ docker-compose ps\n        Name                    Command           State           Ports         \n--------------------------------------------------------------------------------\nchnserver_chnserver_1   /sbin/runsvdir -P         Up      127.0.0.1:443- 443/tcp\n                        /etc/service                      , 0.0.0.0:80- 80/tcp  \nchnserver_hpfeeds_1     /sbin/runsvdir -P         Up      10000/tcp             \n                        /etc/service                                            \nchnserver_mnemosyne_1   /sbin/runsvdir -P         Up      8181/tcp              \n                        /etc/service                                            \nchnserver_mongodb_1     /sbin/runsvdir -P         Up      27017/tcp             \n                        /etc/service                                            \nchnserver_redis_1       /sbin/runsvdir -P         Up      6379/tcp              \n                        /etc/service   When you're ready, the server can be stopped by running  docker-compose down .  For now, to continue with the setup, reset the default admin account (admin@localhost) password from the auto-generated one-time password:  $ docker-compose exec chnserver python /opt/manual_password_reset.py\nEnter email address: admin@localhost\nEnter new password:\nEnter new password (again):\nuser found, updating password  You can now log into the web interface for your new honeypot management server.  In a browser, navigate to  http:// your.host.name , using the hostname or IP of the host where the Docker containers are running.  You should be able to login using the  admin@localhost  account and the password you just set.  Finally, retrieve your DEPLOY_KEY.  This key is needed to deploy honeypots that talk with the server deployment.  Retrieve it with:  docker-compose exec chnserver awk '/DEPLOY_KEY/' /opt/config.py  Make note of this key to use later (or alternatively, just run the above command again when you need it).", 
            "title": "Deploying the Server"
        }, 
        {
            "location": "/quickstart/#next-steps", 
            "text": "At this point you have a functioning CommunityHoneyNetwork server, ready to register honeypots and start collecting data.  Next, try  deploying your first honeypot ...", 
            "title": "Next Steps"
        }, 
        {
            "location": "/firstpot/", 
            "text": "Deploying your First Honeypot\n\n\nThis example covers how to build and deploy an example \nCowrie honeypot\n and connect it to a running CommunityHoneyNetwork server for collection of data.\n\n\nPrerequisites\n\n\nThe default deployment model uses Docker and Docker Compose to deploy containers for the project's tools, and so, require the following:\n\n\n\n\nDocker \n= 1.13.1\n\n\nDocker Compose \n= 1.15.0\n\n\n\n\nBuilding and Deploying Cowrie\n\n\nAs an example, we'll deploy Cowrie with SSH listening on port 2222.  This is not likely helpful in a production deployment, but will serve as an example for creating a honeypot, registering a new sensor with the management server, and capturing attack data.  For more details on production deployments, see the full \nCowrie Documentation\n.\n\n\nCopy the following Docker Compose yaml, and save it as \ndocker-compose.yml\n:\n\n\nversion: '2'\nservices:\n  cowrie:\n    build:\n      context: https://github.com/CommunityHoneyNetwork/cowrie\n      dockerfile: Dockerfile-centos\n    image: cowrie:centos\n    volumes:\n      - ./cowrie.sysconfig:/etc/sysconfig/cowrie\n      - ./cowrie:/etc/cowrie\n    ports:\n      - \n2222:2222\n\n\n\n\n\nThis will tell docker-compose to build the Cowrie container image from the files in the \nCommunityHoneyNetwork Cowrie repository\n, map port 2222 on the host to port 2222 on the container (the default SSH port in the container), and mount two volumes: \n\n\n\n\n./cowrie as /etc/cowrie - to persist the registration information from the management server\n\n\n./cowrie.sysconfig as /etc/sysconfig/cowrie - configuration file for Cowrie (see below)\n\n\n\n\nBefore starting the container, copy the following and save it as \ncowrie.sysconfig\n, setting the \nFEEDS_SERVER\n to the ip or hostname of the management server the honeypot will be reporting to, and \nDEPLOY_KEY\n to the deploy key from the management server.\n\n\nIf you haven't yet setup a management server, follow the \nQuickstart Guide\n\n\n#\n# This can be modified to change the default setup of the cowrie unattended installation\n\nDEBUG=false\n\n# Server to stream data to\nFEEDS_SERVER=\nIP.OR.NAME.OF.YOUR.CHNSERVER\n\nFEEDS_SERVER_PORT=\n10000\n\n\n# Deploy key from the FEEDS_SERVER administrator\n# This is a REQUIRED value\nDEPLOY_KEY=\nYOUR_DEPLOY_KEY\n\n\n# Registration information file\n# If running in a container, this needs to persist\n# COWRIE_JSON=\n/etc/cowrie.json\n\n# SSH Listen Port\n# Can be set to 22 for deployments on real servers\n# or left at 2222 and have the port mapped if deployed\n# in a container\nSSH_LISTEN_PORT=2222\n\n\n\n\nBuild the container images for the Cowrie container:\n\n\n$ docker-compose build\n\n\n\nWhen the images are built, start the honeypot with:\n\n\n$ docker-compose up -d\n\n\n\nYou can verify the honeypot is running with \ndocker-compose ps\n:\n\n\n$ docker-compose ps\n     Name                    Command              State           Ports         \n--------------------------------------------------------------------------------\ncowrie_centos_1   /sbin/runsvdir -P               Up      0.0.0.0:2222-\n2222/tcp\n              /etc/service\n\n\n\nWhen you're ready, the honeypot can be stopped by running \ndocker-compose down\n from the directory containing the docker-compose.yml file.\n\n\nYour new honeypot should show up within the web interface of your management server under the \nSensors\n tab, with the hostname of the container and the UUID that was stored in the cowrie.json file during registration.  As it detects attempts to login to it's fake SSH client, it will send this attack info to the management server.\n\n\n\n\nAbove: A containerized sensor registered to the managment server\n\n\nYou can now test the honeypot logging by trying to log into the false ssh client running on port 2222:\n\n\n$ ssh \nip.of.your.honeypot.host\n -P 2222\n\n\n\nAttacks logged to your management server will show up under the \nAttacks\n section in the web interface.\n\n\n\n\nAbove: The Attack Report page of the managment server, showing a logged hit to the Cowrie honeypot\n\n\nTroubleshooting\n\n\n\n\nIf cowrie is unable to register with the management server, make sure your host can communitcate with the management server on port 80 (check host and network firewall rules, etc).", 
            "title": "Your First Honeypot"
        }, 
        {
            "location": "/firstpot/#deploying-your-first-honeypot", 
            "text": "This example covers how to build and deploy an example  Cowrie honeypot  and connect it to a running CommunityHoneyNetwork server for collection of data.", 
            "title": "Deploying your First Honeypot"
        }, 
        {
            "location": "/firstpot/#prerequisites", 
            "text": "The default deployment model uses Docker and Docker Compose to deploy containers for the project's tools, and so, require the following:   Docker  = 1.13.1  Docker Compose  = 1.15.0", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/firstpot/#building-and-deploying-cowrie", 
            "text": "As an example, we'll deploy Cowrie with SSH listening on port 2222.  This is not likely helpful in a production deployment, but will serve as an example for creating a honeypot, registering a new sensor with the management server, and capturing attack data.  For more details on production deployments, see the full  Cowrie Documentation .  Copy the following Docker Compose yaml, and save it as  docker-compose.yml :  version: '2'\nservices:\n  cowrie:\n    build:\n      context: https://github.com/CommunityHoneyNetwork/cowrie\n      dockerfile: Dockerfile-centos\n    image: cowrie:centos\n    volumes:\n      - ./cowrie.sysconfig:/etc/sysconfig/cowrie\n      - ./cowrie:/etc/cowrie\n    ports:\n      -  2222:2222   This will tell docker-compose to build the Cowrie container image from the files in the  CommunityHoneyNetwork Cowrie repository , map port 2222 on the host to port 2222 on the container (the default SSH port in the container), and mount two volumes:    ./cowrie as /etc/cowrie - to persist the registration information from the management server  ./cowrie.sysconfig as /etc/sysconfig/cowrie - configuration file for Cowrie (see below)   Before starting the container, copy the following and save it as  cowrie.sysconfig , setting the  FEEDS_SERVER  to the ip or hostname of the management server the honeypot will be reporting to, and  DEPLOY_KEY  to the deploy key from the management server.  If you haven't yet setup a management server, follow the  Quickstart Guide  #\n# This can be modified to change the default setup of the cowrie unattended installation\n\nDEBUG=false\n\n# Server to stream data to\nFEEDS_SERVER= IP.OR.NAME.OF.YOUR.CHNSERVER \nFEEDS_SERVER_PORT= 10000 \n\n# Deploy key from the FEEDS_SERVER administrator\n# This is a REQUIRED value\nDEPLOY_KEY= YOUR_DEPLOY_KEY \n\n# Registration information file\n# If running in a container, this needs to persist\n# COWRIE_JSON= /etc/cowrie.json\n\n# SSH Listen Port\n# Can be set to 22 for deployments on real servers\n# or left at 2222 and have the port mapped if deployed\n# in a container\nSSH_LISTEN_PORT=2222  Build the container images for the Cowrie container:  $ docker-compose build  When the images are built, start the honeypot with:  $ docker-compose up -d  You can verify the honeypot is running with  docker-compose ps :  $ docker-compose ps\n     Name                    Command              State           Ports         \n--------------------------------------------------------------------------------\ncowrie_centos_1   /sbin/runsvdir -P               Up      0.0.0.0:2222- 2222/tcp\n              /etc/service  When you're ready, the honeypot can be stopped by running  docker-compose down  from the directory containing the docker-compose.yml file.  Your new honeypot should show up within the web interface of your management server under the  Sensors  tab, with the hostname of the container and the UUID that was stored in the cowrie.json file during registration.  As it detects attempts to login to it's fake SSH client, it will send this attack info to the management server.   Above: A containerized sensor registered to the managment server  You can now test the honeypot logging by trying to log into the false ssh client running on port 2222:  $ ssh  ip.of.your.honeypot.host  -P 2222  Attacks logged to your management server will show up under the  Attacks  section in the web interface.   Above: The Attack Report page of the managment server, showing a logged hit to the Cowrie honeypot", 
            "title": "Building and Deploying Cowrie"
        }, 
        {
            "location": "/firstpot/#troubleshooting", 
            "text": "If cowrie is unable to register with the management server, make sure your host can communitcate with the management server on port 80 (check host and network firewall rules, etc).", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/config/", 
            "text": "Advanced Configuration\n\n\nEach of the services and honeypots in the CommunityHoneyNetwork project should work together out of the box following the \nQuickstart Guide\n. More advanced configuration options can be configured using an /etc/sysconfig/\n or /etc/default/\n file for CentOS-based or Ubuntu-based systems, respectively.\n\n\nServices running in Docker containers can be configured this way as well, mounting the configuration files into place using the \n--volume\n argument for Docker.\n\n\nUsing Docker/docker-compose, each of the containers can share a single sysconfig file, mounted into the appropriate location for each.  Options not appropriate for each particular service are just unused.\n\n\nThe following is an example of a shared configuration file, using default values:\n\n\n# CHN Server options\nCHNSERVER_DEBUG=false\n\nEMAIL=admin@localhost\nSERVER_BASE_URL='http://127.0.0.1'\nHONEYMAP_URL=''\n\nMAIL_SERVER='127.0.0.1'\nMAIL_PORT=25\nMAIL_TLS='y'\nMAIL_SSL='y'\nMAIL_USERNAME=''\nMAIL_PASSWORD=''\nDEFAULT_MAIL_SENDER=''\n\n# Redis config options\nREDIS_URL='redis://redis:6379'\n\n# MongoDB config options\nMONGODB_HOST='mongodb'\nMONGODB_PORT=27017\n\n# HPfeeds config options\nHPFEEDS_HOST='hpfeeds'\nHPFEEDS_PORT=10000\n\n# Mnemosyne config options\nIGNORE_RFC1918=False", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/config/#advanced-configuration", 
            "text": "Each of the services and honeypots in the CommunityHoneyNetwork project should work together out of the box following the  Quickstart Guide . More advanced configuration options can be configured using an /etc/sysconfig/  or /etc/default/  file for CentOS-based or Ubuntu-based systems, respectively.  Services running in Docker containers can be configured this way as well, mounting the configuration files into place using the  --volume  argument for Docker.  Using Docker/docker-compose, each of the containers can share a single sysconfig file, mounted into the appropriate location for each.  Options not appropriate for each particular service are just unused.  The following is an example of a shared configuration file, using default values:  # CHN Server options\nCHNSERVER_DEBUG=false\n\nEMAIL=admin@localhost\nSERVER_BASE_URL='http://127.0.0.1'\nHONEYMAP_URL=''\n\nMAIL_SERVER='127.0.0.1'\nMAIL_PORT=25\nMAIL_TLS='y'\nMAIL_SSL='y'\nMAIL_USERNAME=''\nMAIL_PASSWORD=''\nDEFAULT_MAIL_SENDER=''\n\n# Redis config options\nREDIS_URL='redis://redis:6379'\n\n# MongoDB config options\nMONGODB_HOST='mongodb'\nMONGODB_PORT=27017\n\n# HPfeeds config options\nHPFEEDS_HOST='hpfeeds'\nHPFEEDS_PORT=10000\n\n# Mnemosyne config options\nIGNORE_RFC1918=False", 
            "title": "Advanced Configuration"
        }, 
        {
            "location": "/nondocker/", 
            "text": "Deploying without Docker\n\n\nIn addition to running within Docker, you can also deploy each of the CHN Server services and honeypots as regular services on a host (or many hosts).  The container images are all built using \nAnsible\n playbooks.  These playbooks can be run on regular hosts to install the services as normal services, without running as Docker containers.\n\n\nNote:\n BETA STATUS - The ability to install directly to regular hosts \nshould\n work, but is still in development and \nmight\n break something.  Use at your own risk.  You're most likely to be successful installing on a freshly installed system, rather than a shared host.\n\n\nPrerequesites\n\n\nThe non-containerized deployment model uses Ansible to install and setup hosts.\n\n* Ansible \n= 2.3.2.0\n\n\nExample Deployment\n\n\nAs an example of a non-container deployment, to install the \nMongoDB service\n on the current host:\n\n\ncd /opt\ngit clone https://github.com/CommunityHoneyNetwork/mongodb/\ncd mongodb\necho \"localhost ansible_connection=local\" inventory.txt\nansible-playbook mongodb.yml -i inventory.txt -c local\n\n\n\nThe inventory file can be modified to deploy to remote hosts, as well.  In fact, \nAnsible is incredibly configurable\n, and all of the playbooks could be combined with an appropriate inventory file to manage all of the hosts with a single Ansible setup.\n\n\nSupported Operating Systems\n\n\nThe CommunityHoneyNetwork projects are developed and tested to work with:\n\n\n\n\nCentOS 7\n\n\nUbuntu 17.10\n\n\n\n\nThey \nshould\n also work with the following, but are currently untested and unsupported:\n\n\n\n\nFedora 26\n\n\nRed Hat Enterprise Linux 7\n\n\nDebian Stretch\n\n\n\n\nRequires Advanced Configuration\n\n\nThe out-of-the-box configuration of each service is designed for use inside a container and by default, when installed without contianers, the services need additional information to know how to talk with one another.  Read the \nAdvanced Configuration\n documentation for more information.\n\n\nRunit\n\n\nEach of the projects use \nRunit\n as the process manager for their respective services, whether in containers or not.  The Ansible playbooks will install Runit along with the services.  This should not impact systems using SysVinit or Systemd.  Since Ansible will install the services using packages provided by the OS maintainer, there will be appropriate configuration files for the init system of that OS, but without the Runit configs, the services will not be setup correctly to talk to one another.\n\n\nRunit services can be controlled directly using the \nRunit sv command\n.  All CNH services on the host can be started at once by using the \nRunit runsvdir command\n: \nrunsvdir -P /etc/service\n.\n\n\nStartup scripts for each service exist in /etc/service/\n/run.\n\n\nInstallation Locations\n\n\nMost of the services will use the upstream packages for your OS or Python PIP packages, and install in the standard locations for those packages.\n\n\nServices that are not available as upstream packages or PIP packages will install to /opt on your host.", 
            "title": "Deploying without Docker"
        }, 
        {
            "location": "/nondocker/#deploying-without-docker", 
            "text": "In addition to running within Docker, you can also deploy each of the CHN Server services and honeypots as regular services on a host (or many hosts).  The container images are all built using  Ansible  playbooks.  These playbooks can be run on regular hosts to install the services as normal services, without running as Docker containers.  Note:  BETA STATUS - The ability to install directly to regular hosts  should  work, but is still in development and  might  break something.  Use at your own risk.  You're most likely to be successful installing on a freshly installed system, rather than a shared host.", 
            "title": "Deploying without Docker"
        }, 
        {
            "location": "/nondocker/#prerequesites", 
            "text": "The non-containerized deployment model uses Ansible to install and setup hosts. \n* Ansible  = 2.3.2.0", 
            "title": "Prerequesites"
        }, 
        {
            "location": "/nondocker/#example-deployment", 
            "text": "As an example of a non-container deployment, to install the  MongoDB service  on the current host:  cd /opt\ngit clone https://github.com/CommunityHoneyNetwork/mongodb/\ncd mongodb\necho \"localhost ansible_connection=local\" inventory.txt\nansible-playbook mongodb.yml -i inventory.txt -c local  The inventory file can be modified to deploy to remote hosts, as well.  In fact,  Ansible is incredibly configurable , and all of the playbooks could be combined with an appropriate inventory file to manage all of the hosts with a single Ansible setup.", 
            "title": "Example Deployment"
        }, 
        {
            "location": "/nondocker/#supported-operating-systems", 
            "text": "The CommunityHoneyNetwork projects are developed and tested to work with:   CentOS 7  Ubuntu 17.10   They  should  also work with the following, but are currently untested and unsupported:   Fedora 26  Red Hat Enterprise Linux 7  Debian Stretch", 
            "title": "Supported Operating Systems"
        }, 
        {
            "location": "/nondocker/#requires-advanced-configuration", 
            "text": "The out-of-the-box configuration of each service is designed for use inside a container and by default, when installed without contianers, the services need additional information to know how to talk with one another.  Read the  Advanced Configuration  documentation for more information.", 
            "title": "Requires Advanced Configuration"
        }, 
        {
            "location": "/nondocker/#runit", 
            "text": "Each of the projects use  Runit  as the process manager for their respective services, whether in containers or not.  The Ansible playbooks will install Runit along with the services.  This should not impact systems using SysVinit or Systemd.  Since Ansible will install the services using packages provided by the OS maintainer, there will be appropriate configuration files for the init system of that OS, but without the Runit configs, the services will not be setup correctly to talk to one another.  Runit services can be controlled directly using the  Runit sv command .  All CNH services on the host can be started at once by using the  Runit runsvdir command :  runsvdir -P /etc/service .  Startup scripts for each service exist in /etc/service/ /run.", 
            "title": "Runit"
        }, 
        {
            "location": "/nondocker/#installation-locations", 
            "text": "Most of the services will use the upstream packages for your OS or Python PIP packages, and install in the standard locations for those packages.  Services that are not available as upstream packages or PIP packages will install to /opt on your host.", 
            "title": "Installation Locations"
        }, 
        {
            "location": "/kubernetes/", 
            "text": "Deploying with Kubernetes\n\n\nComing soon", 
            "title": "Deploying on Kubernetes"
        }, 
        {
            "location": "/kubernetes/#deploying-with-kubernetes", 
            "text": "Coming soon", 
            "title": "Deploying with Kubernetes"
        }, 
        {
            "location": "/cloud/", 
            "text": "Deploying to cloud providers\n\n\nComing soon \n\n\nProviders:\n\n\n\n\nAmazon Web Services\n\n\nMicrosoft Azure\n\n\nGoogle Compute Engine", 
            "title": "Deploying to cloud providers"
        }, 
        {
            "location": "/cloud/#deploying-to-cloud-providers", 
            "text": "Coming soon   Providers:   Amazon Web Services  Microsoft Azure  Google Compute Engine", 
            "title": "Deploying to cloud providers"
        }, 
        {
            "location": "/cowrie/", 
            "text": "Cowrie Honeypot\n\n\nThe CommunityHoneyNetwork Cowrie Honeypot is an implementation of \n@micheloosterhof's Cowrie\n, configured to report logged attacks to the CommunityHoneyNetwork management server.\n\n\n\n\n\"Cowrie is a medium interaction SSH and Telnet honeypot designed to log brute force attacks and the shell interaction performed by the attacker.\"\n\n\n\n\nConfiguring Cowrie to talk to the CHN management server\n\n\nPrior to starting, Cowrie will parse some options from \n/etc/sysconfig/cowrie\n for RedHat-based or \n/etc/default/cowrie\n for Debian-based systems or containers.  The following is an example config file:\n\n\n#\n# This can be modified to change the default setup of the cowrie unattended installation\n\nDEBUG=false\n\n# Server to stream data to\nFEEDS_SERVER=\nhttp://localhost\n\nFEEDS_SERVER_PORT=\n10000\n\n\n# Deploy key from the FEEDS_SERVER administrator\n# This is a REQUIRED value\nDEPLOY_KEY=\n\n# Registration information file\n# If running in a container, this needs to persist\n# COWRIE_JSON=\n/etc/cowrie/cowrie.json\n\n# SSH Listen Port\n# Can be set to 22 for deployments on real servers\n# or left at 2222 and have the port mapped if deployed \n# in a container\nSSH_LISTEN_PORT=2222\n\n\n\n\n\nConfiguration Options\n\n\nThe following options are supported in the \n/etc/sysconfig/cowrie\n and \n/etc/default/cowrie files\n:\n\n\n\n\nDEBUG: (boolean) Enable more verbose output to the console\n\n\nFEEDS_SERVER: (string) The hostname or IP address of the HPFeeds server to send logged events.  This is likely going to be the CHN management server.\n\n\nFEEDS_SERVER_PORT: (integer) The HPFeeds port.  Default is 10000.\n\n\nDEPLOY_KEY: (string; REQUIRED) The deploy key provided by the feeds server administration for registration during the first startup.  This key is \nrequired\n for registration.\n\n\nCOWRIE_JSON: (string) The location to store the registration information returned from the HPFeeds server.\n\n\nSSH_LISTEN_PORT: (integer) The port for the Cowrie daemon to listen on for SSH connections.  In containerized applications, this is \ninside the container\n, and the port can still be mapped to a different port on the host.\n\n\n\n\nDeploying Cowrie with Docker and docker-compose\n\n\nDeploying Cowrie with Docker and docker-compose is covered in the \nYour First Honeypot\n documentation.\n\n\nDeploying Cowrie without Docker\n\n\nWhile deploying Cowrie in a container is the strongly suggested method, it can be deployed directly on a host, without the use of Docker, by running an \nAnsible\n playbook.\n\n\nThe warnings, prerequisites, supported operating systems and other notes from the overall \nDeploying Without Docker\n documentation apply.\n\n\nTo deploy the latest CommunityHoneyNetwork Cowrie honeypot without Docker:\n\n\ncd /opt\ngit clone https://github.com/CommunityHoneyNetwork/cowrie/\ncd cowrie\necho \"localhost ansible_connection=local\" inventory.txt\nansible-playbook cowrie.yml -i inventory.txt -c local\n\n\n\nAfter installation, adjust the \n/etc/sysconfig/cowrie\n or \n/etc/default/cowrie\n file as described above to register the honeypot with the CHN management server.\n\n\nAs with other CommunityHoneyNetwork projects, Cowrie relies on \nRunit\n as its process manager.   See the \nRunit Section\n section of the Deploying Without Docker documentation for more information.\n\n\nAcknowledgements\n\n\nCommunityHoneyNetwork Cowrie container is an adaptation of \n@micheloosterhof's Cowrie\n Cowrie software and \nThreatstream's Modern Honey Network\n Cowrie \n HPFeeds work, among other contributors and collaborators.\n\n\nLicense\n\n\nThe Cowrie software is \nCopyright (c) 2009 Upi Tamminen\n All rights reserved.\n\n\nThe ThreatStream implementation of Cowrie with HPFeeds, upon which CommunityHoneyNetwork is based is licensed under the \nGNU LESSER GENERAL PUBLIC LICENSE Version 2.1\n\n\nThe \nCommunityHoneyNetwork Cowrie deployment model and code\n is therefore also licensed under the \nGNU LESSER GENERAL PUBLIC LICENSE Version 2.1", 
            "title": "Cowrie"
        }, 
        {
            "location": "/cowrie/#cowrie-honeypot", 
            "text": "The CommunityHoneyNetwork Cowrie Honeypot is an implementation of  @micheloosterhof's Cowrie , configured to report logged attacks to the CommunityHoneyNetwork management server.   \"Cowrie is a medium interaction SSH and Telnet honeypot designed to log brute force attacks and the shell interaction performed by the attacker.\"", 
            "title": "Cowrie Honeypot"
        }, 
        {
            "location": "/cowrie/#configuring-cowrie-to-talk-to-the-chn-management-server", 
            "text": "Prior to starting, Cowrie will parse some options from  /etc/sysconfig/cowrie  for RedHat-based or  /etc/default/cowrie  for Debian-based systems or containers.  The following is an example config file:  #\n# This can be modified to change the default setup of the cowrie unattended installation\n\nDEBUG=false\n\n# Server to stream data to\nFEEDS_SERVER= http://localhost \nFEEDS_SERVER_PORT= 10000 \n\n# Deploy key from the FEEDS_SERVER administrator\n# This is a REQUIRED value\nDEPLOY_KEY=\n\n# Registration information file\n# If running in a container, this needs to persist\n# COWRIE_JSON= /etc/cowrie/cowrie.json\n\n# SSH Listen Port\n# Can be set to 22 for deployments on real servers\n# or left at 2222 and have the port mapped if deployed \n# in a container\nSSH_LISTEN_PORT=2222", 
            "title": "Configuring Cowrie to talk to the CHN management server"
        }, 
        {
            "location": "/cowrie/#configuration-options", 
            "text": "The following options are supported in the  /etc/sysconfig/cowrie  and  /etc/default/cowrie files :   DEBUG: (boolean) Enable more verbose output to the console  FEEDS_SERVER: (string) The hostname or IP address of the HPFeeds server to send logged events.  This is likely going to be the CHN management server.  FEEDS_SERVER_PORT: (integer) The HPFeeds port.  Default is 10000.  DEPLOY_KEY: (string; REQUIRED) The deploy key provided by the feeds server administration for registration during the first startup.  This key is  required  for registration.  COWRIE_JSON: (string) The location to store the registration information returned from the HPFeeds server.  SSH_LISTEN_PORT: (integer) The port for the Cowrie daemon to listen on for SSH connections.  In containerized applications, this is  inside the container , and the port can still be mapped to a different port on the host.", 
            "title": "Configuration Options"
        }, 
        {
            "location": "/cowrie/#deploying-cowrie-with-docker-and-docker-compose", 
            "text": "Deploying Cowrie with Docker and docker-compose is covered in the  Your First Honeypot  documentation.", 
            "title": "Deploying Cowrie with Docker and docker-compose"
        }, 
        {
            "location": "/cowrie/#deploying-cowrie-without-docker", 
            "text": "While deploying Cowrie in a container is the strongly suggested method, it can be deployed directly on a host, without the use of Docker, by running an  Ansible  playbook.  The warnings, prerequisites, supported operating systems and other notes from the overall  Deploying Without Docker  documentation apply.  To deploy the latest CommunityHoneyNetwork Cowrie honeypot without Docker:  cd /opt\ngit clone https://github.com/CommunityHoneyNetwork/cowrie/\ncd cowrie\necho \"localhost ansible_connection=local\" inventory.txt\nansible-playbook cowrie.yml -i inventory.txt -c local  After installation, adjust the  /etc/sysconfig/cowrie  or  /etc/default/cowrie  file as described above to register the honeypot with the CHN management server.  As with other CommunityHoneyNetwork projects, Cowrie relies on  Runit  as its process manager.   See the  Runit Section  section of the Deploying Without Docker documentation for more information.", 
            "title": "Deploying Cowrie without Docker"
        }, 
        {
            "location": "/cowrie/#acknowledgements", 
            "text": "CommunityHoneyNetwork Cowrie container is an adaptation of  @micheloosterhof's Cowrie  Cowrie software and  Threatstream's Modern Honey Network  Cowrie   HPFeeds work, among other contributors and collaborators.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/cowrie/#license", 
            "text": "The Cowrie software is  Copyright (c) 2009 Upi Tamminen  All rights reserved.  The ThreatStream implementation of Cowrie with HPFeeds, upon which CommunityHoneyNetwork is based is licensed under the  GNU LESSER GENERAL PUBLIC LICENSE Version 2.1  The  CommunityHoneyNetwork Cowrie deployment model and code  is therefore also licensed under the  GNU LESSER GENERAL PUBLIC LICENSE Version 2.1", 
            "title": "License"
        }
    ]
}